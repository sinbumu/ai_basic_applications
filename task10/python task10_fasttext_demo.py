"""
Word Embedding ì‹¤ìŠµ ìŠ¤í¬ë¦½íŠ¸ (FastText ë²„ì „)
â¦ ì˜ì–´ NLTK movie_reviews ì½”í¼ìŠ¤ â†’ fastText Skip-gram í•™ìŠµ
â¦ ìœ ì‚¬ë„ / ì•„ë‚ ë¡œì§€ ê³„ì‚° â†’ ì¶œë ¥
â¦ t-SNE ì‹œê°í™” â†’ PNG ì €ì¥
ì‹¤í–‰:  python task10_fasttext_demo.py
"""

import os, re, random, pathlib, itertools, math
import nltk, fasttext, fasttext.util
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 1) ë°ì´í„° ì¤€ë¹„
print("â–¶ NLTK corpus download / preprocess â€¦")
nltk.download('movie_reviews', quiet=True)
sents = [" ".join(tokens) for tokens in nltk.corpus.movie_reviews.sents()]
corpus_path = pathlib.Path("movie_reviews.txt")
corpus_path.write_text("\n".join(sents), encoding="utf-8")
print(f"âœ“ ì˜í™”ë¦¬ë·° ë¬¸ì¥ìˆ˜ = {len(sents):,}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 2) FastText Skip-gram í•™ìŠµ
print("\nâ–¶ fastText training â€¦ (10 epoch, 200-dim)")
model = fasttext.train_unsupervised(
    str(corpus_path),
    model="skipgram",
    dim=200,
    ws=5,
    epoch=10,
    minn=3, maxn=6,   # subword
    thread=os.cpu_count() or 4
)
model.save_model("movie_reviews_ft.bin")
print("âœ“ ëª¨ë¸ ì €ì¥: movie_reviews_ft.bin")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 3) ìœ ì‚¬ë„ & ì•„ë‚ ë¡œì§€
def cosine(u, v):
    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v) + 1e-9)

print("\nâ–¶ ë‹¨ì–´ ìœ ì‚¬ë„(actor ~ actress)")
sim = cosine(model.get_word_vector("actor"), model.get_word_vector("actress"))
print(f"    cosine(actor, actress) = {sim:.4f}")

def analogy(a, b, c, topn=5):
    target = model.get_word_vector(a) - model.get_word_vector(b) + model.get_word_vector(c)
    words, scores = [], []
    for w in itertools.islice(model.get_words(), 50000):   # ìƒìœ„ 5ë§Œ ë‹¨ì–´ë§Œ íƒìƒ‰
        v = model.get_word_vector(w)
        score = cosine(target, v)
        words.append(w); scores.append(score)
    best = sorted(zip(words, scores), key=lambda x: -x[1])
    return [w for w, _ in best if w not in (a, b, c)][:topn]

print("â–¶ ì•„ë‚ ë¡œì§€: king - man + woman â‰ˆ ?")
print("   ", analogy("king", "man", "woman", 5))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 4) t-SNE ì‹œê°í™”
print("\nâ–¶ t-SNE (500 words) â†’ png â€¦")
words = model.get_words()[:500]
vecs  = np.vstack([model.get_word_vector(w) for w in words])

tsne  = TSNE(n_components=2, perplexity=40, random_state=0, n_iter=1200)
coords = tsne.fit_transform(vecs)

plt.figure(figsize=(12, 8))
plt.scatter(coords[:, 0], coords[:, 1], s=8)
for (x, y), w in zip(coords, words):
    plt.annotate(w, (x, y), fontsize=8)
plt.title("t-SNE of FastText vectors (top-500 movie-review words)")
plt.tight_layout()
plt.savefig("tsne_fasttext_movie_reviews.png", dpi=200)
print("âœ“ ì‹œê°í™” íŒŒì¼: tsne_fasttext_movie_reviews.png")

print("\nğŸ‰ ì‹¤ìŠµ ì™„ë£Œ!  ìŠ¤í¬ë¦½íŠ¸ê°€ ìƒì„±í•œ PNGì™€ ì½˜ì†” ê²°ê³¼ë¥¼ ê³¼ì œ ë³´ê³ ì„œì— ìº¡ì²˜í•˜ì„¸ìš”.")
